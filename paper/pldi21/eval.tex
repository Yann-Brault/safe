\section{Evaluation}\label{sec:eval}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{img/conc-analysis-time}
  \vspace*{-1.5em}
  \caption{Analysis time for Lodash 4 \textit{original} tests without (no-DS)
  and with (DS) dynamic shortcuts within 5 minutes}
  \label{fig:conc-analysis-time}
  \vspace*{-1.5em}
\end{figure}

We evaluated our tool based on the following three research questions:
\begin{itemize}
\item \textbf{RQ1) Analysis Speed-up:} How much analysis time is reduced by
using dynamic shortcuts during static analysis?
\item \textbf{RQ2) Precision Improvement:} How much analysis precision is
improved by using dynamic shortcuts instead of manual modeling?
\item \textbf{RQ3) Opaque Function Coverage:} How many opaque functions are
covered by dynamic shortcuts without using manual modeling?
\end{itemize}
We selected the official 306 tests of Lodash 4
(v.4.17.20)\footnote{https://github.com/lodash/lodash/blob/4.17.20/test/test.js}
used in the motivating examples in Section~\ref{sec:motivation} as our evaluation target.
The most recent papers about JavaScript static analysis techniques~\cite{value-refinement,
value-partitioning} also used the tests to evaluate their techniques.
Among them, we filtered out \inred{37} tests that use JavaScript language
features SAFE does not support such as dynamic code generation using
\jscode{Function}, getters and setters, and browser-specific features like $\jscode{__proto__}$.
Thus, we used \inred{269} out of 306 tests for the evaluation of $\tool$.
We performed our experiments on a Ubuntu machine
equipped with 4.2GHz Quad-Core Intel Core i7 and 64GB of RAM.


\subsection{Analysis Speed-up}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{img/abs-analysis-time}
  \vspace*{-1.5em}
  \caption{Analysis time for Lodash 4 \textit{abstracted} tests without (no-DS)
  and with (DS) dynamic shortcuts within 5 minutes}
  \label{fig:abs-analysis-time}
  \vspace*{-1.5em}
\end{figure}

To evaluate the effectiveness of using dynamic shortcuts, we performed static
analysis of \inred{269} Lodash 4 tests with and without dynamic shortcuts.
Figure~\ref{fig:conc-analysis-time} depicts histograms for their analysis
time and a box plot for speed up after applying dynamic shortcuts.
While the baseline analysis (no-DS) finished analysis of \inred{199} out of \inred{269} tests within 5
minutes, our tool (DS) finished analysis of all tests using dynamic shortcuts.
For \inred{199} tests analyzable by both analyzers, on average, the analysis took \inred{168.4}
seconds for no-DS and \inred{12.2} seconds for DS, which shows that
using dynamic shortcuts outperforms the baseline analyzer \inred{20.16}\textsf{x} on average.
Only for one test using $\jscode{_.sample}$, a Lodash 4 library
function that randomly samples a value from a given array, DS showed
\inred{0.81}\textsf{x} speed of no-DS due to frequent use of
dynamic shortcuts, that is \inred{24} times.

Note that since most Lodash 4 tests use concrete values instead of
non-deterministic user inputs, they can be analyzed by a few number of dynamic shortcuts.
In fact, among \inred{269} tests, \inred{262} tests are analyzed
by a single dynamic shortcut without using abstract semantics.
However, in real-world JavaScript programs, arguments of library
functions may include non-deterministic user inputs.
To evaluate our approach in a real-world setting,
we modified Lodash 4 official tests with abstract values to simulate actual use patterns of library functions.
We mad abstract values by randomly selecting literals and replacing
one of them with its corresponding abstract value.
For example, if we select a numeric literal \jscode{42}, we modified it to the abstract numeric value
$\top_{\code{num}}$, which represents all the numeric values.
In the remaining section, we evaluated $\tool$ using the \textit{original} tests
and the \textit{abstracted} tests of Lodash 4.

For abstracted tests as well, dynamic shortcuts successfully accelerated the static analysis.
Figure~\ref{fig:abs-analysis-time} shows the analysis time of the abstracted tests.
Among \inred{269} abstracted tests, no-DS finished analysis of \inred{82} tests within 5 minutes,
but DS finished analysis of \inred{219} tests.  For \inred{82} tests analyzable by both analyzers,
on average, the analyses took \inred{168.4} seconds for no-DS and \inred{12.2} seconds for DS,
which shows that dynamic shortcuts outperforms the baseline analyzer
\inred{20.16}\textsf{x} on average.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{img/abs-analysis-ratio}
  \vspace*{-1.5em}
  \caption{Analysis time ratio for \inred{219} \textit{abstracted} tests}
  \label{fig:abs-analysis-ratio}
  \vspace*{-1.5em}
\end{figure}

Unlike for the original tests, analysis of \inred{82}
abstracted tests that are analyzable by both analyzers invoked
\inred{xx} dynamic shortcuts.  Because taking a dynamic shortcut
requires converting between abstract states and sealed symbolic values
and exchanging them between the static analyzer and the dynamic analyzer,
using dynamic shortcuts multiple times may incur more performance
overhead than performance benefits by using sealed symbolic execution.
One may conjecture that the communication cost between the static
analyzer and the dynamic analyzer may be proportional to the number of
dynamic shortcuts.

To experimentally evaluate the conjecture, we investigated the relationship between
the communication cost between analyzers and the number of dynamic shortcuts.
For \inred{xx} original tests, the communication cost was only
\inred{x.xx}\% of the total analysis time.  However, for \inred{xx}
abstracted tests, the communication cost was \inred{xx.xx}\% of the
total analysis time.  Figure~\ref{fig:abs-analysis-ratio} presents the
analysis time ratio for \inred{82} abstracted tests.
The $x$-axis represents the time ratio normalized by the total analysis time with dynamic shortcuts
and the $y$-axis denotes the number of dynamic shortcuts and the number of corresponding tests.
For all \inred{82} tests, the communication cost (DS-Comm.) is larger than
both the static analysis time (DS-Static) and the dynamic analysis
time (DS-Dynamic).  When dynamic shortcuts are performed less than 10 times,
the communication cost is modest compared with the baseline static
analysis time (no-DS).  However, the more dynamic shortcuts are performed,
the less the performance benefits by using sealed symbolic execution.
Specifically, when dynamic shortcuts are performed more than
\inred{30} times, DS-Comm. is even larger than no-DS.
Based on this evaluation result, we believe that we can leverage
dynamic shortcuts by optimizing the communication between static and dynamic analyzers.

\begin{figure}[t]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\linewidth]{img/conc-precision}
    \vspace*{-1.5em}
    \caption{Reachable branches for \inred{xx} \textit{original} tests}
    \label{fig:precision-fail}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\linewidth]{img/abs-precision}
    \vspace*{-1.5em}
    \caption{Reachable branches for \inred{82} \textit{abstracted} tests}
    \label{fig:precision-branch}
  \end{subfigure}
  \vspace*{-1em}
  \caption{Branch coverage of analysis without (no-DS) and with (DS) dynamic shortcuts}
  \label{fig:precision}
  \vspace*{-1.5em}
\end{figure}


\begin{table*}[t]
  \centering
  \caption{The number of \textit{abstracted} tests using dynamic shortcut
  instead of manual modeling for each JavaScript built-in library}
  \label{table:func-replace}
  \vspace*{-1em}
  \scriptsize
  \[
    \begin{array}{c|l|@{~}r@{~}c@{~}r@{~}r@{~}?c|l|@{~}r@{~}c@{~}r@{~}r@{~}?c|l|@{~}r@{~}c@{~}r@{~}r@{~}}

      \myhead{Object}       {Function}        {\# Replaced}

      \mysucc{2}{Boolean}   {Boolean}         {214}{214}{100} & \mydata{1}{}            {new Object}        {214}{214}{100} & \mymult{2}{Number}      {valueOf}       {214}{214}{100} \mylineff
      \mydata{1}{}          {new Boolean}     {214}{214}{100} & \mydata{1}{}            {getPrototypeOf}    {214}{214}{100} & \myname{1}{.prototype}                                  \mylinetft
      \mydata{1}{Array}     {isArray}         {214}{214}{100} & \mydata{1}{}            {create}            {214}{214}{100} & \mymult{2}{RegExp}      {toString}      {214}{214}{100} \mylinetf
      \mydata{1}{}          {toString}        { 92}{139}{ 66} & \mydata{1}{Object}      {preventExtensions} {214}{214}{100} & \myname{1}{.prototype}                                  \mylinefft
      \mydata{1}{}          {toLocaleString}  {193}{214}{ 90} & \mydata{1}{}            {isFrozen}          {214}{214}{100} & \mydata{2}{String}      {String}        {214}{214}{100} \mylinefff
      \mydata{1}{}          {concat}          {214}{214}{100} & \mydata{1}{}            {isExtensible}      {214}{214}{100} & \mydata{1}{}            {fromCharCode}  {214}{214}{100} \mylinefft
      \mydata{1}{}          {join}            {214}{214}{100} & \mydata{1}{}            {keys}              {214}{214}{100} & \mydata{1}{}            {charAt}        {214}{214}{100} \mylineftf
      \mysucc{1}{Array}     {pop}             {214}{214}{100} & \mydata{1}{Object}      {valueOf}           {214}{214}{100} & \mydata{1}{}            {charCodeAt}    {214}{214}{100} \mylinefff
      \mydata{1}{.prototype}{push}            {214}{214}{100} & \mydata{1}{.prototype}  {isPrototypeOf}     {214}{214}{100} & \mydata{1}{}            {indexOf}       {214}{214}{100} \mylineftf
      \mydata{1}{}          {slice}           {214}{214}{100} & \mydata{1}{}            {acos}              {214}{214}{100} & \mysucc{1}{}            {match}         {214}{214}{100} \mylinefff
      \mydata{1}{}          {splice}          {214}{214}{100} & \mysucc{1}{}            {atan2}             {214}{214}{100} & \mydata{1}{String}      {replace}       {214}{214}{100} \mylinefff
      \mydata{1}{}          {map}             {214}{214}{100} & \mydata{1}{}            {cos}               {214}{214}{100} & \mydata{1}{.prototype}  {splice}        {214}{214}{100} \mylinefff
      \mydata{1}{}          {reduce}          {214}{214}{100} & \mydata{1}{Math}        {exp}               {214}{214}{100} & \mydata{1}{}            {split}         {214}{214}{100} \mylinetff
      \mysucc{1}{global}    {eval}            {214}{214}{100} & \mydata{1}{}            {floor}             {214}{214}{100} & \mysucc{1}{}            {substring}     {214}{214}{100} \mylinetff
      \mydata{1}{}          {new Date}        {214}{214}{100} & \mydata{1}{}            {max}               {214}{214}{100} & \mydata{1}{}            {toLowerCase}   {214}{214}{100} \mylinefff
      \mydata{1}{Date}      {parse}           {214}{214}{100} & \mydata{1}{}            {min}               {214}{214}{100} & \mydata{1}{}            {toUpperCase}   {214}{214}{100} \mylinef
      \mydata{1}{}          {now}             {214}{214}{100}
    \end{array}
  \]
  \vspace*{-1em}
\end{table*}

\subsection{Precision Improvement}

To evaluate the analysis precision improvement of dynamic shortcuts,
we measured the number of branches covered by no-DS and DS.
Because both no-DS and DS are designed to be sound,
high (low) branch coverage denotes low (high) analysis precision.

Figure~\ref{fig:precision} depicts the comparison of the analysis
precision between no-DS and DS.  The $x$-axis and the $y$-axis denote
the number of branches covered by no-DS and DS, respectively;
each $\times$ mark denotes each test.  The top and bottom dotted lines
denote the worst and the best precision improvement, respectively, and
the middle solid line denotes the average improvement.
For \inred{xx} original tests that are analyzable by both analyzers,
Figure~\ref{fig:precision}(a) shows that dynamic shortcuts
successfully reduced the number of covered branches at least
\inred{1.00}\textsc{x}, at most \inred{0.54}\textsc{x}, and \inred{0.92}x on average.
For \inred{xx} abstracted tests that are analyzable by both analyzers,
Figure~\ref{fig:precision}(b) shows that dynamic shortcuts
also successfully cut down the number of covered branches at least
\inred{0.81}\textsc{x}, at most \inred{0.51}\textsc{x}, and \inred{0.68}\textsc{x} on average.


\subsection{Opaque Function Coverage}
To evaluate how much manual modeling efforts of opaque functions
are reduced by dynamic shortcuts, we measured the number of tests where
opaque functions that are analyzed only by dynamic analysis not by
static analysis.  Table~\ref{table:func-replace} summarizes the result.
For \inred{xx} original tests and \inred{xx} abstracted tests, we measured the
number of tests that use only dynamic shortcuts instead of manual modeling
for each JavaScript built-in library function.  For each row,
\textbf{Object} column denotes a built-in object,
\textbf{Function} a function name, and
\inred{\textbf{\# Replaced} the number of tests successfully replacing manual
modeling via dynamic shortcuts with the total number of tests using the target function.
For example, the fourth row in the left side describes that \jscode{Array.prototype.toString} is used in
\inred{139} original tests and \inred{xxx} abstracted tests.
 Among them, \inred{44} original tests \inred{xx} abstracted tests are successfully analyzed
by dynamic shortcuts instead of using the modeling of
\jscode{Array.prototype.toString}.
Moreover, several built-in functions are analyzed by only dynamic shortcuts in
all tests.  Among \inred{49} JavaScript built-in functions, \inred{xx} and
\inred{xx} functions are analyzed by only dynamic shortcut instead of manual
modeling for all original and all abstracted tests, respectively.  Each filled cell
describes fully replaceable cases in Table~\ref{table:func-replace}.
Therefore, dynamic shortcuts effectively lessen
the burden of manual modeling for JavaScript built-in functions.
}
